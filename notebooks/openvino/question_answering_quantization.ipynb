{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaed3927-e315-46d3-8889-df3f3bbcbf6b",
   "metadata": {},
   "source": [
    "# Quantize a Hugging Face Question-Answering Model with OpenVINO\n",
    "\n",
    "This notebook shows how to quantize a question answering model with OpenVINO's Neural Network Compression Framework (NNCF). Question-answering models can understand and answer questions based on a given context, such as a paragraph of text or a document. \n",
    "\n",
    "OpenVINO is a toolkit for accelerated inference on Intel hardware, including CPUs and integrated GPUs. This allows developers to deploy Hugging Face's NLP models in a wide range of scenarios, from small edge devices to large cloud environments.\n",
    "\n",
    "To install the requirements for using this notebook, please do `pip install optimum[openvino,nncf] datasets evaluate[evaluator]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0407fc92-c052-47b7-8721-01836adf3b54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venvs/openvino_13722_nov25_env/lib/python3.8/site-packages/nncf/torch/__init__.py:23: UserWarning: NNCF provides best results with torch==1.9.1, while current torch version is 1.13.0+cu117 - consider switching to torch==1.9.1\n",
      "  warnings.warn(\"NNCF provides best results with torch=={bkc}, \"\n",
      "/home/ubuntu/venvs/openvino_13722_nov25_env/lib/python3.8/site-packages/nncf/torch/dynamic_graph/patch_pytorch.py:163: UserWarning: Not patching unique_dim since it is missing in this version of PyTorch\n",
      "  warnings.warn(\"Not patching {} since it is missing in this version of PyTorch\".format(op_name))\n",
      "/home/ubuntu/venvs/openvino_13722_nov25_env/lib/python3.8/site-packages/openvino/offline_transformations/__init__.py:10: FutureWarning: The module is private and following namespace `offline_transformations` will be removed in the future, use `openvino.runtime.passes` instead!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from evaluate import evaluator\n",
    "from optimum.intel.openvino import OVConfig, OVModelForQuestionAnswering, OVQuantizer\n",
    "from transformers import (\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    "    EvalPrediction,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "from utils.trainer_qa import QuestionAnsweringTrainer\n",
    "from utils.utils_qa import (\n",
    "    post_processing_function_qa,\n",
    "    prepare_train_features,\n",
    "    prepare_validation_features,\n",
    ")\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a16fe-2bc0-477e-b8d6-02a4f7508f03",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "We define MODEL_ID and DATASET_NAME, and the paths for the quantized model files. VERSION_2_WITH_NEGATIVE should be set to TRUE if a version of the SQuAD v2 dataset is used, which includes questions that do not have an answer. \n",
    "\n",
    "For this tutorial, we use the [Stanford Question Answering Dataset (SQuAD)](https://huggingface.co/datasets/squad), a reading comprehension dataset, consisting of questions on a set of Wikipedia articles, where the answer to every question is a segment of text from a given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32f9a76-414b-43d9-9769-af131223f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"csarron/bert-base-uncased-squad-v1\"\n",
    "# When using a different dataset then SQuAD v1, please edit the constants at the top of utils/utils_qa.py\n",
    "DATASET_NAME = \"squad\"\n",
    "VERSION_2_WITH_NEGATIVE = False\n",
    "\n",
    "base_model_path = Path(f\"models/{MODEL_ID}\")\n",
    "fp32_model_path = base_model_path.with_name(base_model_path.name + \"_FP32\")\n",
    "int8_ptq_model_path = base_model_path.with_name(base_model_path.name + \"_INT8_PTQ\")\n",
    "int8_qat_model_path = base_model_path.with_name(base_model_path.name + \"_INT8_QAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3547df-5603-41b4-8752-df5fb7347be0",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer\n",
    "\n",
    "We load the model from the Hugging Face Hub. The model will be automatically downloaded if it has not been downloaded before, or loaded from the cache otherwise.\n",
    "\n",
    "We also load the tokenizer, which converts the questions and contexts from the dataset to tokens: numerical values in the format the model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38641b14-07d0-49d5-af86-8b5247ae39d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 7592, 2088, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_ID)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# See how the tokenizer converts input text to model input values\n",
    "print(tokenizer(\"hello world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124bd9ad-077c-4f41-b579-0bf978fe6a1e",
   "metadata": {},
   "source": [
    "## Preview the Dataset\n",
    "\n",
    "The `datasets` library makes it easy to load datasets. Common datasets can be loaded from the Hugging Face Hub by providing the name of the dataset. See https://github.com/huggingface/datasets. We can load the SQuAD dataset with `load_dataset` and show a random dataset item. Every dataset item in the SQuAD dataset has a unique id, a title which denotes the category, a context and a question, and answers. The answer is a subset of the context, and both the text of the answer, and the start position of the answer in the context (answer_start) are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602fe46f-c96a-4a0f-9338-58339d466f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fee5d6020840938f4b33521b937c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '570e53690b85d914000d7e3c',\n",
       " 'title': 'Melbourne',\n",
       " 'context': \"Melbourne is experiencing high population growth, generating high demand for housing. This housing boom has increased house prices and rents, as well as the availability of all types of housing. Subdivision regularly occurs in the outer areas of Melbourne, with numerous developers offering house and land packages. However, after 10 years[when?] of planning policies to encourage medium-density and high-density development in existing areas with greater access to public transport and other services, Melbourne's middle and outer-ring suburbs have seen significant brownfields redevelopment.\",\n",
       " 'question': 'What effect has the housing boom had on house prices and rents?',\n",
       " 'answers': {'text': ['increased'], 'answer_start': [108]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(DATASET_NAME)\n",
    "dataset[\"train\"][31415]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4dfc2d-f007-4455-8043-edc5468b87e2",
   "metadata": {},
   "source": [
    "## Post Training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483309f-0b12-4c10-ab0b-58c50981f495",
   "metadata": {
    "tags": []
   },
   "source": [
    "For post-training quantization (PTQ) we start with a Hugging Face AutoModel, in this case AutoModelForQuestionAnswering. The quantizer also needs a dataset. \n",
    "\n",
    "To quantize a model with post-training quantization, we define an `OVQuantizer`, attach a dataset, and call the `quantize` method. That's all!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14899a-3aec-46b6-9d4b-332452e9cb25",
   "metadata": {},
   "source": [
    "### Prepare the Dataset\n",
    "\n",
    "We need a representative dataset to quantize the model. The SQuAD dataset is pretrained on a large dataset with a wide variety of questions and answers, and it generalizes pretty well to questions and contexts it has never seen before. For production use, you would finetune this dataset with questions and context specific to your domain. In this notebook, we use a subset of the SQuAD dataset, for demonstration purposes. We chose the _Super Bowl 50_ category from the validation subset of SQuAD because it has a large number of questions.\n",
    "\n",
    "Post-training quantization does not need a training and validation dataset, but we define these splits here to allow doing quantization-aware training later in this notebook, and to make sure we're using the same dataset split for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be68958-ce5e-4cc6-b8e7-2867feaf084b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(examples, tokenizer):\n",
    "    return tokenizer(examples[\"question\"], examples[\"context\"], padding=True, truncation=True, max_length=384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4dde1a-1ba6-470c-afe8-7169c04282dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN_ITEMS = 600\n",
    "filtered_examples = dataset[\"validation\"].filter(lambda x: x[\"title\"].startswith(\"Super_Bowl_50\"))\n",
    "train_examples = filtered_examples.select(range(0, NUM_TRAIN_ITEMS))\n",
    "train_dataset = train_examples.map(lambda x: preprocess_fn(x, tokenizer), batched=True)\n",
    "\n",
    "validation_examples = filtered_examples.select(range(NUM_TRAIN_ITEMS, len(filtered_examples)))\n",
    "validation_dataset = validation_examples.map(lambda x: preprocess_fn(x, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b0738-fdc9-4557-97bf-b4c6709280cc",
   "metadata": {},
   "source": [
    "### Quantize the Model with Post Training Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31c5415e-e22b-4ab9-b903-8791e80b188d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hide PyTorch warnings about missing shape inference\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Quantize the model\n",
    "quantizer = OVQuantizer.from_pretrained(model)\n",
    "quantizer.quantize(calibration_dataset=train_dataset, save_directory=int8_ptq_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a52092-e352-47ef-9ed2-89508bc48d70",
   "metadata": {},
   "source": [
    "### Show accuracy difference\n",
    "\n",
    "We load the quantized model and the original FP32 model, and compare the metrics on both models. The [evaluate](https://github.com/huggingface/evaluate) library makes it very easy to evaluate models on a given dataset, with a given metric. For the SQuAD dataset, an F1 score and exact_match metric are returned.\n",
    "\n",
    "For loading the quantized model with OpenVINO, we use `OVModelForQuestionAnswering`. It can be used in the same way as [`AutoModelForQuestionAnswering`](https://huggingface.co/docs/transformers/main/model_doc/auto).\n",
    "\n",
    "The evaluator is called with a [Pipeline](https://huggingface.co/docs/transformers/main/en/pipeline_tutorial) which we will also use later on to show inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2f615a-19e3-4ee2-9309-2ae1392c7f62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP32</th>\n",
       "      <td>82.86</td>\n",
       "      <td>86.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT8 PTQ</th>\n",
       "      <td>80.00</td>\n",
       "      <td>85.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          exact_match     f1\n",
       "FP32            82.86  86.33\n",
       "INT8 PTQ        80.00  85.13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model_ptq = OVModelForQuestionAnswering.from_pretrained(int8_ptq_model_path)\n",
    "original_model = AutoModelForQuestionAnswering.from_pretrained(MODEL_ID)\n",
    "ov_qa_pipeline_ptq = pipeline(\"question-answering\", model=quantized_model_ptq, tokenizer=tokenizer)\n",
    "hf_qa_pipeline = pipeline(\"question-answering\", model=original_model, tokenizer=tokenizer)\n",
    "\n",
    "squad_eval = evaluator(\"question-answering\")\n",
    "\n",
    "ov_eval_results = squad_eval.compute(\n",
    "    model_or_pipeline=ov_qa_pipeline_ptq,\n",
    "    data=validation_examples,\n",
    "    metric=\"squad\",\n",
    "    squad_v2_format=VERSION_2_WITH_NEGATIVE,\n",
    ")\n",
    "\n",
    "hf_eval_results = squad_eval.compute(\n",
    "    model_or_pipeline=hf_qa_pipeline,\n",
    "    data=validation_examples,\n",
    "    metric=\"squad\",\n",
    "    squad_v2_format=VERSION_2_WITH_NEGATIVE,\n",
    ")\n",
    "pd.DataFrame.from_records(\n",
    "    [hf_eval_results, ov_eval_results], columns=[\"exact_match\", \"f1\"], index=[\"FP32\", \"INT8 PTQ\"]\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b5d25-b248-4249-ab90-900b117e7ff3",
   "metadata": {},
   "source": [
    "### Compare model size\n",
    "\n",
    "Quantization reduces the size of the model by up to four times. We save the FP32 PyTorch model and define a function to show the model size for the PyTorch and OpenVINO models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eeaa81f-7fc5-49ba-80b8-2d95a1310a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(model_folder, framework):\n",
    "    \"\"\"Return OpenVINO or PyTorch model size in Mb\"\"\"\n",
    "    if framework == \"openvino\":\n",
    "        model_path = Path(model_folder) / \"openvino_model.xml\"\n",
    "        model_size = model_path.stat().st_size + model_path.with_suffix(\".bin\").stat().st_size\n",
    "    elif framework == \"pytorch\":\n",
    "        model_path = Path(model_folder) / \"pytorch_model.bin\"\n",
    "        model_size = model_path.stat().st_size\n",
    "    model_size /= 1024 * 1024\n",
    "    return model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b11965-46b9-4dcf-88d8-dd8e08638b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.391506818835034"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(fp32_model_path)\n",
    "get_model_size(fp32_model_path, \"pytorch\") / get_model_size(int8_ptq_model_path, \"openvino\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c568e-5a9d-4d99-b173-862e1c98b176",
   "metadata": {},
   "source": [
    "## Quantization Aware Training\n",
    "\n",
    "Post training quantization worked reasonably well, but resulted in a drop in exact_match of of a few percentage points. Quantization aware training integrates quantization in the training loop. The \"quantization error\" is added to the loss function, which reduces the accuracy drop in the resulting model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85519857-8147-426a-b70b-f150c9a5dd58",
   "metadata": {},
   "source": [
    "### Prepare data for QuestionAnsweringTrainer\n",
    "\n",
    "The QuestionAnsweringTrainer expects the data to be formatted in a specific way. We use the train and validation examples from the post training quantization example, and map them to a dataset formatted for quantization aware training.\n",
    "\n",
    "The `prepare_train_features`, `prepare_validation_features` and `post_processing_function_qa` functions were adapted from the [Question Answering example script](https://github.com/huggingface/optimum-intel/tree/main/examples/openvino/question-answering).  Please check out the [bert_utils](bert_utils.py) file to see how they are defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b464e1d-f7f2-4bef-9d54-a0b936588fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_qat = train_examples.map(\n",
    "    lambda x: prepare_train_features(x, tokenizer, True),\n",
    "    batched=True,\n",
    "    remove_columns=train_examples.column_names,\n",
    "    load_from_cache_file=True,  # not data_args.overwrite_cache,\n",
    "    desc=\"Running tokenizer on train dataset\",\n",
    ")\n",
    "\n",
    "validation_dataset_qat = validation_examples.map(\n",
    "    lambda x: prepare_validation_features(x, tokenizer, True),\n",
    "    batched=True,\n",
    "    remove_columns=validation_examples.column_names,\n",
    "    load_from_cache_file=True,  # not data_args.overwrite_cache,\n",
    "    desc=\"Running tokenizer on validation dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372a1c2d-a719-4149-92f0-65c3e4a12cfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Quantize the Model with Quantization Aware Training\n",
    "\n",
    "For quantization aware training, we create a QuestionAnsweringTrainer. This Trainer is defined in [trainer_qa.py](trainer_qa.py) and taken from the [Question Answering example](https://github.com/huggingface/optimum-intel/tree/main/examples/openvino/question-answering). It is a modified version of the standard Hugging Face [QuestionAnsweringTrainer](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering) that adds quantization aware training with [NNCF](https://github.com/openvinotoolkit/nncf/). See the Hugging Face [Trainer documentation](https://huggingface.co/docs/transformers/main_classes/trainer) for more information on the Trainer class.\n",
    "\n",
    "Apart from the standard training arguments, the QuestionAnsweringTrainer for NNCF requires an `ov_config` parameter with quantization settings. The default `OVConfig()` settings should work well for many cases. For more information about modifying the settings, or to understand what the settings mean, please refer to the [NNCF quantization documentation](https://github.com/openvinotoolkit/nncf/blob/develop/docs/compression_algorithms/Quantization.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1afcc609-c0fe-4739-89f6-1c798cf74518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'quantization',\n",
       " 'preset': 'mixed',\n",
       " 'overflow_fix': 'disable',\n",
       " 'initializer': {'range': {'num_init_samples': 300, 'type': 'mean_min_max'},\n",
       "  'batchnorm_adaptation': {'num_bn_adaptation_samples': 0}},\n",
       " 'scope_overrides': {'activations': {'{re}.*matmul_0': {'mode': 'symmetric'}}},\n",
       " 'ignored_scopes': ['{re}.*Embeddings.*',\n",
       "  '{re}.*__add___[0-1]',\n",
       "  '{re}.*layer_norm_0',\n",
       "  '{re}.*matmul_1',\n",
       "  '{re}.*__truediv__*'],\n",
       " 'export_to_onnx_standard_ops': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the quantization configuration\n",
    "OVConfig().compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f6d8449-663a-4278-b33d-46a9c80958ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in models/csarron/bert-base-uncased-squad-v1_INT8_QAT/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 353.8682, 'train_samples_per_second': 3.504, 'train_steps_per_second': 0.441, 'train_loss': 0.7849663954514724, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models/csarron/bert-base-uncased-squad-v1_INT8_QAT/pytorch_model.bin\n",
      "tokenizer config file saved in models/csarron/bert-base-uncased-squad-v1_INT8_QAT/tokenizer_config.json\n",
      "Special tokens file saved in models/csarron/bert-base-uncased-squad-v1_INT8_QAT/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    \"\"\"Helper function for metric computation in training loop\"\"\"\n",
    "    return metric.compute(predictions=p.predictions, references=p.label_ids)\n",
    "\n",
    "\n",
    "metric = evaluate.load(\"squad_v2\" if VERSION_2_WITH_NEGATIVE else \"squad\")\n",
    "ov_config = OVConfig()\n",
    "ov_config.compression[\"overflow_fix\"] = \"disable\"\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(MODEL_ID)\n",
    "\n",
    "\n",
    "trainer = QuestionAnsweringTrainer(\n",
    "    model=model,\n",
    "    ov_config=ov_config,\n",
    "    feature=\"question-answering\",\n",
    "    args=TrainingArguments(int8_qat_model_path, num_train_epochs=2.0, do_train=True, do_eval=True),\n",
    "    train_dataset=train_dataset_qat,\n",
    "    eval_dataset=validation_dataset_qat,\n",
    "    eval_examples=validation_examples,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    post_process_function=post_processing_function_qa,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "train_result = trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eabede-7177-4cfe-847d-8b9102226e4e",
   "metadata": {},
   "source": [
    "### Show accuracy difference\n",
    "\n",
    "We use the same evaluator as we did for Post Training Quantization, and show the results of all three models (FP32, INT8 PTQ and INT8 QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e96f078-2744-430e-9057-ed381238c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/csarron/bert-base-uncased-squad-v1_INT8_QAT/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"models/csarron/bert-base-uncased-squad-v1_INT8_QAT/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"NNCFNetwork\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FP32</th>\n",
       "      <td>82.86</td>\n",
       "      <td>86.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT8 PTQ</th>\n",
       "      <td>80.00</td>\n",
       "      <td>85.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT QAT</th>\n",
       "      <td>79.52</td>\n",
       "      <td>81.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          exact_match     f1\n",
       "FP32            82.86  86.33\n",
       "INT8 PTQ        80.00  85.13\n",
       "INT QAT         79.52  81.09"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_eval = evaluator(\"question-answering\")\n",
    "\n",
    "quantized_model_qat = OVModelForQuestionAnswering.from_pretrained(int8_qat_model_path)\n",
    "ov_qa_pipeline_qat = pipeline(\"question-answering\", model=quantized_model_qat, tokenizer=tokenizer)\n",
    "ov_eval_results_qat = squad_eval.compute(\n",
    "    model_or_pipeline=ov_qa_pipeline_qat,\n",
    "    data=validation_examples,\n",
    "    metric=\"squad\",\n",
    "    squad_v2_format=VERSION_2_WITH_NEGATIVE,\n",
    ")\n",
    "eval_results = [hf_eval_results, ov_eval_results, ov_eval_results_qat]\n",
    "df = pd.DataFrame.from_records(eval_results, columns=[\"exact_match\", \"f1\"], index=[\"FP32\", \"INT8 PTQ\", \"INT QAT\"])\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14dc07-086e-435e-bf3d-e74f1f6860cf",
   "metadata": {},
   "source": [
    "## Show inference\n",
    "\n",
    "Hugging Face `pipeline`'s simplify inference on a model. A pipeline is created by adding a task, model and tokenizer to the `pipeline` function. Inference is then as simple as `qa_pipeline(\"question\", \"context\").\n",
    "\n",
    "We created three pipelines earlier in this notebook: `hf_qa_pipeline`, `ov_qa_pipeline_ptq` and `ov_qa_pipeline_qat` for the FP32 Hugging Face model and the INT8 PTQ and QAT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e23fe96-8d7f-4aa1-816f-707ca1a2f978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super Bowl 50 featured numerous records from individuals and teams. Denver won despite being massively outgained in total yards (315 to 194) and first downs (21 to 11). Their 194 yards and 11 first downs were both the lowest totals ever by a Super Bowl winning team. The previous record was 244 yards by the Baltimore Ravens in Super Bowl XXXV. Only seven other teams had ever gained less than 200 yards in a Super Bowl, and all of them had lost. The Broncos' seven sacks tied a Super Bowl record set by the Chicago Bears in Super Bowl XX. Kony Ealy tied a Super Bowl record with three sacks. Jordan Norwood's 61-yard punt return set a new record, surpassing the old record of 45 yards set by John Taylor in Super Bowl XXIII. Denver was just 1-of-14 on third down, while Carolina was barely better at 3-of-15. The two teams' combined third down conversion percentage of 13.8 was a Super Bowl low. Manning and Newton had quarterback passer ratings of 56.6 and 55.4, respectively, and their added total of 112 is a record lowest aggregate passer rating for a Super Bowl. Manning became the oldest quarterback ever to win a Super Bowl at age 39, and the first quarterback ever to win a Super Bowl with two different teams, while Gary Kubiak became the first head coach to win a Super Bowl with the same franchise he went to the Super Bowl with as a player.\n"
     ]
    }
   ],
   "source": [
    "context = validation_examples[200][\"context\"]\n",
    "question = \"Who won the game?\"\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1168f1c-14de-4aad-977d-122a8d366935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Denver'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_qa_pipeline(question, context)[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c885d378-2842-49d0-b583-a2fc023558b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Denver'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ov_qa_pipeline_ptq(question, context)[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d6e0a25-9282-4b54-b42a-faad17c478a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Baltimore Ravens'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ov_qa_pipeline_qat(question, context)[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db183795-6dae-4ef6-847d-042223264149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T21:25:39.912874Z",
     "iopub.status.busy": "2022-11-07T21:25:39.912662Z",
     "iopub.status.idle": "2022-11-07T21:25:39.916029Z",
     "shell.execute_reply": "2022-11-07T21:25:39.915541Z",
     "shell.execute_reply.started": "2022-11-07T21:25:39.912859Z"
    }
   },
   "source": [
    "## Compare Inference of FP32 and INT8 models\n",
    "\n",
    "Metrics like exact match and F1 score give an impression of the quality of the model, but to get a better sense of the quality of the model, it's always useful to look at model predictions. In the next cell, we go over the items in the validation set, and display the items where the FP32 prediction score is different than the INT8 prediction score. In this example we compare the FP32 model with the QAT model; it can also be insightful to compare the PTQ model and the QAT model.\n",
    "\n",
    "The results show that for some predictions, the FP32 model is better, but for others, the INT8 model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "256e4b8c-a791-4668-95e3-4d23720fcf94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>FP32 answer</th>\n",
       "      <th>FP32 F1</th>\n",
       "      <th>INT8 answer</th>\n",
       "      <th>INT8 F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which company won a contest to have their ad shown for free during Super Bowl 50?</td>\n",
       "      <td>[Death Wish Coffee, Death Wish Coffee, Death Wish Coffee]</td>\n",
       "      <td>QuickBooks</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Death Wish Coffee</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What company had a contest to win a free Super Bowl commercial?</td>\n",
       "      <td>[QuickBooks., QuickBooks, QuickBooks]</td>\n",
       "      <td>QuickBooks</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Death Wish Coffee</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What movie company paid to have the next Jason Bourne movie ad shown during the Super Bowl?</td>\n",
       "      <td>[Universal, Universal, Universal]</td>\n",
       "      <td>Universal</td>\n",
       "      <td>100.00</td>\n",
       "      <td>20th Century Fox, Lionsgate, Paramount Pictures, Universal Studios</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What company paid for a Super Bowl 50 ad to show a trailer of X-Men: Apocalypse?</td>\n",
       "      <td>[Fox, Fox, Disney]</td>\n",
       "      <td>20th Century Fox, Lionsgate</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who handled the play-by-play for WBT?</td>\n",
       "      <td>[Mick Mixon, Mick Mixon, Mick Mixon]</td>\n",
       "      <td>Mick Mixon</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Dave Logan</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What two radio stations in Denver carried Super Bowl 50?</td>\n",
       "      <td>[KOA (850 AM) and KRFX (103.5 FM), KOA (850 AM) and KRFX (103.5 FM), KOA (850 AM) and KRFX (103.5 FM)]</td>\n",
       "      <td>KOA (850 AM) and KRFX</td>\n",
       "      <td>83.33</td>\n",
       "      <td>KRFX (103.5 FM)</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who lead the halftime show of Super Bowl 50?</td>\n",
       "      <td>[Coldplay., Coldplay, Coldplay]</td>\n",
       "      <td>Coldplay</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who headlined the Super Bowl 50 halftime show?</td>\n",
       "      <td>[Coldplay., Coldplay, Coldplay]</td>\n",
       "      <td>Coldplay</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Bruno Mars</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Who was at the receiving end of a 22-yard pass from Peyton Manning?</td>\n",
       "      <td>[Andre Caldwell, Andre Caldwell, Caldwell]</td>\n",
       "      <td>Andre Caldwell</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Owen Daniels</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How many yards was the pass on the first drive?</td>\n",
       "      <td>[18, 18, 22-yard]</td>\n",
       "      <td>18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Who scored the first points for Denver?</td>\n",
       "      <td>[Brandon McManus, Brandon McManus, McManus]</td>\n",
       "      <td>Brandon McManus</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Peyton Manning</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>When is the last time a fumble return touchdown happened in a Super Bowl?</td>\n",
       "      <td>[Super Bowl XXVIII, the end of the 1993 season, 1993]</td>\n",
       "      <td>1993 season</td>\n",
       "      <td>66.67</td>\n",
       "      <td>Super Bowl XXVIII</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How many yards was the field goal that made the score 13-7 in Super Bowl 50?</td>\n",
       "      <td>[33, 33, 33]</td>\n",
       "      <td>33</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How did the drive end for the Panthers?</td>\n",
       "      <td>[punt, Newton was sacked, sacked]</td>\n",
       "      <td>The Panthers could not gain any yards with their possession and had to punt</td>\n",
       "      <td>14.29</td>\n",
       "      <td>punt.</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Who did Newton get a pass to in the Panther starting plays of Super Bowl 50?</td>\n",
       "      <td>[Ted Ginn Jr., Ted Ginn Jr]</td>\n",
       "      <td>Ted Ginn Jr.</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Corey Brown</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How many of the following three fourth quarter drives after the field goal makng the score 16-10 ended in punts?</td>\n",
       "      <td>[three, three, The next three drives]</td>\n",
       "      <td>three</td>\n",
       "      <td>100.00</td>\n",
       "      <td>one</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Who fumbled the ball on 3rd-and-9?</td>\n",
       "      <td>[Newton, Newton, Newton]</td>\n",
       "      <td>Miller stripped the ball away from Newton</td>\n",
       "      <td>28.57</td>\n",
       "      <td>Miller</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What Panther defender was called for holding on third down?</td>\n",
       "      <td>[Josh Norman, Josh Norman, Norman]</td>\n",
       "      <td>Josh Norman</td>\n",
       "      <td>100.00</td>\n",
       "      <td>Ward</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How many total tackles did Charles Johnson have in Super Bowl 50?</td>\n",
       "      <td>[four, four, four]</td>\n",
       "      <td>four</td>\n",
       "      <td>100.00</td>\n",
       "      <td>seven</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How many first downs did Denver have?</td>\n",
       "      <td>[11, 11, 11]</td>\n",
       "      <td>21 to 11</td>\n",
       "      <td>50.00</td>\n",
       "      <td>11</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>How many yards did Denver have for Super Bowl 50?</td>\n",
       "      <td>[194, 194, 194]</td>\n",
       "      <td>315 to 194</td>\n",
       "      <td>50.00</td>\n",
       "      <td>194</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How many first downs did Denver have for Super Bowl 50?</td>\n",
       "      <td>[11, 11, 11]</td>\n",
       "      <td>21 to 11</td>\n",
       "      <td>50.00</td>\n",
       "      <td>11</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How many first downs did the Panthers have in Super Bowl 50?</td>\n",
       "      <td>[21, 21, 21]</td>\n",
       "      <td>21 to 11</td>\n",
       "      <td>50.00</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>How many first downs did the Broncos have in Super Bowl 50?</td>\n",
       "      <td>[11, 11, 11]</td>\n",
       "      <td>21 to 11</td>\n",
       "      <td>50.00</td>\n",
       "      <td>11</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>How many teams has Manning won the Super Bowl with?</td>\n",
       "      <td>[two, two, two]</td>\n",
       "      <td>two</td>\n",
       "      <td>100.00</td>\n",
       "      <td>seven</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            Question  \\\n",
       "0                                  Which company won a contest to have their ad shown for free during Super Bowl 50?   \n",
       "1                                                    What company had a contest to win a free Super Bowl commercial?   \n",
       "2                        What movie company paid to have the next Jason Bourne movie ad shown during the Super Bowl?   \n",
       "3                                   What company paid for a Super Bowl 50 ad to show a trailer of X-Men: Apocalypse?   \n",
       "4                                                                              Who handled the play-by-play for WBT?   \n",
       "5                                                           What two radio stations in Denver carried Super Bowl 50?   \n",
       "6                                                                       Who lead the halftime show of Super Bowl 50?   \n",
       "7                                                                     Who headlined the Super Bowl 50 halftime show?   \n",
       "8                                                Who was at the receiving end of a 22-yard pass from Peyton Manning?   \n",
       "9                                                                    How many yards was the pass on the first drive?   \n",
       "10                                                                           Who scored the first points for Denver?   \n",
       "11                                         When is the last time a fumble return touchdown happened in a Super Bowl?   \n",
       "12                                      How many yards was the field goal that made the score 13-7 in Super Bowl 50?   \n",
       "13                                                                           How did the drive end for the Panthers?   \n",
       "14                                      Who did Newton get a pass to in the Panther starting plays of Super Bowl 50?   \n",
       "15  How many of the following three fourth quarter drives after the field goal makng the score 16-10 ended in punts?   \n",
       "16                                                                                Who fumbled the ball on 3rd-and-9?   \n",
       "17                                                       What Panther defender was called for holding on third down?   \n",
       "18                                                 How many total tackles did Charles Johnson have in Super Bowl 50?   \n",
       "19                                                                             How many first downs did Denver have?   \n",
       "20                                                                 How many yards did Denver have for Super Bowl 50?   \n",
       "21                                                           How many first downs did Denver have for Super Bowl 50?   \n",
       "22                                                      How many first downs did the Panthers have in Super Bowl 50?   \n",
       "23                                                       How many first downs did the Broncos have in Super Bowl 50?   \n",
       "24                                                               How many teams has Manning won the Super Bowl with?   \n",
       "\n",
       "                                                                                                    Answer  \\\n",
       "0                                                [Death Wish Coffee, Death Wish Coffee, Death Wish Coffee]   \n",
       "1                                                                    [QuickBooks., QuickBooks, QuickBooks]   \n",
       "2                                                                        [Universal, Universal, Universal]   \n",
       "3                                                                                       [Fox, Fox, Disney]   \n",
       "4                                                                     [Mick Mixon, Mick Mixon, Mick Mixon]   \n",
       "5   [KOA (850 AM) and KRFX (103.5 FM), KOA (850 AM) and KRFX (103.5 FM), KOA (850 AM) and KRFX (103.5 FM)]   \n",
       "6                                                                          [Coldplay., Coldplay, Coldplay]   \n",
       "7                                                                          [Coldplay., Coldplay, Coldplay]   \n",
       "8                                                               [Andre Caldwell, Andre Caldwell, Caldwell]   \n",
       "9                                                                                        [18, 18, 22-yard]   \n",
       "10                                                             [Brandon McManus, Brandon McManus, McManus]   \n",
       "11                                                   [Super Bowl XXVIII, the end of the 1993 season, 1993]   \n",
       "12                                                                                            [33, 33, 33]   \n",
       "13                                                                       [punt, Newton was sacked, sacked]   \n",
       "14                                                                             [Ted Ginn Jr., Ted Ginn Jr]   \n",
       "15                                                                   [three, three, The next three drives]   \n",
       "16                                                                                [Newton, Newton, Newton]   \n",
       "17                                                                      [Josh Norman, Josh Norman, Norman]   \n",
       "18                                                                                      [four, four, four]   \n",
       "19                                                                                            [11, 11, 11]   \n",
       "20                                                                                         [194, 194, 194]   \n",
       "21                                                                                            [11, 11, 11]   \n",
       "22                                                                                            [21, 21, 21]   \n",
       "23                                                                                            [11, 11, 11]   \n",
       "24                                                                                         [two, two, two]   \n",
       "\n",
       "                                                                    FP32 answer  \\\n",
       "0                                                                    QuickBooks   \n",
       "1                                                                    QuickBooks   \n",
       "2                                                                     Universal   \n",
       "3                                                   20th Century Fox, Lionsgate   \n",
       "4                                                                    Mick Mixon   \n",
       "5                                                         KOA (850 AM) and KRFX   \n",
       "6                                                                      Coldplay   \n",
       "7                                                                      Coldplay   \n",
       "8                                                                Andre Caldwell   \n",
       "9                                                                            18   \n",
       "10                                                              Brandon McManus   \n",
       "11                                                                  1993 season   \n",
       "12                                                                           33   \n",
       "13  The Panthers could not gain any yards with their possession and had to punt   \n",
       "14                                                                 Ted Ginn Jr.   \n",
       "15                                                                        three   \n",
       "16                                    Miller stripped the ball away from Newton   \n",
       "17                                                                  Josh Norman   \n",
       "18                                                                         four   \n",
       "19                                                                     21 to 11   \n",
       "20                                                                   315 to 194   \n",
       "21                                                                     21 to 11   \n",
       "22                                                                     21 to 11   \n",
       "23                                                                     21 to 11   \n",
       "24                                                                          two   \n",
       "\n",
       "    FP32 F1  \\\n",
       "0      0.00   \n",
       "1    100.00   \n",
       "2    100.00   \n",
       "3     40.00   \n",
       "4    100.00   \n",
       "5     83.33   \n",
       "6    100.00   \n",
       "7    100.00   \n",
       "8    100.00   \n",
       "9    100.00   \n",
       "10   100.00   \n",
       "11    66.67   \n",
       "12   100.00   \n",
       "13    14.29   \n",
       "14   100.00   \n",
       "15   100.00   \n",
       "16    28.57   \n",
       "17   100.00   \n",
       "18   100.00   \n",
       "19    50.00   \n",
       "20    50.00   \n",
       "21    50.00   \n",
       "22    50.00   \n",
       "23    50.00   \n",
       "24   100.00   \n",
       "\n",
       "                                                           INT8 answer  \\\n",
       "0                                                    Death Wish Coffee   \n",
       "1                                                    Death Wish Coffee   \n",
       "2   20th Century Fox, Lionsgate, Paramount Pictures, Universal Studios   \n",
       "3                                                   Paramount Pictures   \n",
       "4                                                           Dave Logan   \n",
       "5                                                      KRFX (103.5 FM)   \n",
       "6                                                           Bruno Mars   \n",
       "7                                                           Bruno Mars   \n",
       "8                                                         Owen Daniels   \n",
       "9                                                                   20   \n",
       "10                                                      Peyton Manning   \n",
       "11                                                   Super Bowl XXVIII   \n",
       "12                                                                  10   \n",
       "13                                                               punt.   \n",
       "14                                                         Corey Brown   \n",
       "15                                                                 one   \n",
       "16                                                              Miller   \n",
       "17                                                                Ward   \n",
       "18                                                               seven   \n",
       "19                                                                  11   \n",
       "20                                                                 194   \n",
       "21                                                                  11   \n",
       "22                                                                  11   \n",
       "23                                                                  11   \n",
       "24                                                               seven   \n",
       "\n",
       "    INT8 F1  \n",
       "0    100.00  \n",
       "1      0.00  \n",
       "2     22.22  \n",
       "3      0.00  \n",
       "4      0.00  \n",
       "5     60.00  \n",
       "6      0.00  \n",
       "7      0.00  \n",
       "8      0.00  \n",
       "9      0.00  \n",
       "10     0.00  \n",
       "11   100.00  \n",
       "12     0.00  \n",
       "13   100.00  \n",
       "14     0.00  \n",
       "15     0.00  \n",
       "16     0.00  \n",
       "17     0.00  \n",
       "18     0.00  \n",
       "19   100.00  \n",
       "20   100.00  \n",
       "21   100.00  \n",
       "22     0.00  \n",
       "23   100.00  \n",
       "24     0.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for item in validation_examples:\n",
    "    id, title, context, question, answers = item.values()\n",
    "    fp32_answer = hf_qa_pipeline(question, context)[\"answer\"]\n",
    "    int8_answer = ov_qa_pipeline_qat(question, context)[\"answer\"]\n",
    "\n",
    "    references = [{\"id\": id, \"answers\": answers}]\n",
    "    fp32_predictions = [{\"id\": id, \"prediction_text\": fp32_answer}]\n",
    "    int8_predictions = [{\"id\": id, \"prediction_text\": int8_answer}]\n",
    "\n",
    "    fp32_score = round(metric.compute(references=references, predictions=fp32_predictions)[\"f1\"], 2)\n",
    "    int8_score = round(metric.compute(references=references, predictions=int8_predictions)[\"f1\"], 2)\n",
    "\n",
    "    if int8_score != fp32_score:\n",
    "        results.append((question, answers[\"text\"], fp32_answer, fp32_score, int8_answer, int8_score))\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Question\", \"Answer\", \"FP32 answer\", \"FP32 F1\", \"INT8 answer\", \"INT8 F1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8697a2-0a51-427f-8245-cda56bb8cf18",
   "metadata": {},
   "source": [
    "## Benchmark the Quantized and Original Model\n",
    "\n",
    "Compare the inference speed of the quantized OpenVINO IR model with that of the original PyTorch model.\n",
    "\n",
    "OpenVINO models can optionally be used with static shapes, which increases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8806da79-0b3b-403e-a40c-61db6a0f482d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models/csarron/bert-base-uncased-squad-v1_INT8_QAT/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"models/csarron/bert-base-uncased-squad-v1_INT8_QAT/config.json\",\n",
      "  \"architectures\": [\n",
      "    \"NNCFNetwork\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/ubuntu/.cache/huggingface/hub/models--csarron--bert-base-uncased-squad-v1/snapshots/a39235c4e278ec8b420b46ee11a1ed1a432a7256/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"csarron/bert-base-uncased-squad-v1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/ubuntu/.cache/huggingface/hub/models--csarron--bert-base-uncased-squad-v1/snapshots/a39235c4e278ec8b420b46ee11a1ed1a432a7256/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at csarron/bert-base-uncased-squad-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency of original FP32 model: 37.77 ms\n",
      "Latency of quantized model: 16.77 ms\n",
      "Speedup: 2.25x\n"
     ]
    }
   ],
   "source": [
    "def benchmark(model, static_shapes=True):\n",
    "    \"\"\" \"\"\"\n",
    "    transformers.logging.set_verbosity_error()\n",
    "\n",
    "    kwargs = {}\n",
    "    if static_shapes:\n",
    "        if model.base_model_prefix == \"openvino\":\n",
    "            model.reshape(1, 256)\n",
    "            model.compile()\n",
    "        kwargs = {\"max_seq_len\": 256, \"padding\": \"max_length\", \"truncation\": True}\n",
    "\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, **kwargs)\n",
    "\n",
    "    ds = datasets.load_dataset(\"squad\", split=\"validation[:300]\")\n",
    "    latencies = []\n",
    "    for i, item in enumerate(ds):\n",
    "        start_time = time.perf_counter()\n",
    "        results = qa_pipeline({\"question\": item[\"question\"], \"context\": item[\"context\"]})\n",
    "        end_time = time.perf_counter()\n",
    "        latencies.append(end_time - start_time)\n",
    "\n",
    "    return np.median(latencies) * 1000\n",
    "\n",
    "\n",
    "quantized_model = OVModelForQuestionAnswering.from_pretrained(int8_qat_model_path)\n",
    "original_model = AutoModelForQuestionAnswering.from_pretrained(MODEL_ID)\n",
    "# original_model = OVModelForQuestionAnswering.from_pretrained(\"bert-base-fp32\")\n",
    "\n",
    "\n",
    "original_latency = benchmark(original_model, static_shapes=True)\n",
    "quantized_latency = benchmark(quantized_model, static_shapes=True)\n",
    "\n",
    "print(f\"Latency of original FP32 model: {original_latency:.2f} ms\")\n",
    "print(f\"Latency of quantized model: {quantized_latency:.2f} ms\")\n",
    "print(f\"Speedup: {(original_latency/quantized_latency):.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d64ac5a-fed2-40f6-9ef4-d1ce36e81c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency of original FP32 model: 27.10 ms\n",
      "Latency of quantized model: 23.90 ms\n",
      "Speedup: 1.13x\n"
     ]
    }
   ],
   "source": [
    "original_latency = benchmark(original_model, static_shapes=False)\n",
    "quantized_latency = benchmark(quantized_model, static_shapes=False)\n",
    "\n",
    "print(f\"Latency of original FP32 model: {original_latency:.2f} ms\")\n",
    "print(f\"Latency of quantized model: {quantized_latency:.2f} ms\")\n",
    "print(f\"Speedup: {(original_latency/quantized_latency):.2f}x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
